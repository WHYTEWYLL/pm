# PM Assistant - Architecture

## ğŸ—ï¸ Structure

The project is organized into clear, modular layers following separation of concerns:

```
pm/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ingestion/           # Data sources (fetch raw data)
â”‚   â”‚   â”œâ”€â”€ slack.py         # Slack API client
â”‚   â”‚   â”œâ”€â”€ linear.py        # Linear API client
â”‚   â”‚   â””â”€â”€ github.py        # Future: GitHub API client
â”‚   â”‚
â”‚   â”œâ”€â”€ workflows/           # Business logic orchestration
â”‚   â”‚   â”œâ”€â”€ sync.py          # Sync: fetch & store messages
â”‚   â”‚   â”œâ”€â”€ process.py       # Process: analyze & update Linear
â”‚   â”‚   â””â”€â”€ standup.py       # Generate daily reports
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/             # Data persistence layer
â”‚   â”‚   â””â”€â”€ db.py            # SQLite database operations
â”‚   â”‚
â”‚   â”œâ”€â”€ ai/                  # Intelligence layer
â”‚   â”‚   â””â”€â”€ analyzer.py      # AI-powered message analysis
â”‚   â”‚
â”‚   â”œâ”€â”€ models.py            # Data models (SlackMessage, LinearIssue)
â”‚   â””â”€â”€ config.py            # Configuration management
â”‚
â””â”€â”€ data/                    # Local storage (DB, memory files)
```

---

## ğŸ“¦ Layer Responsibilities

### **Ingestion Layer** (`app/jobs/workflows/ingestion/`)

**Purpose:** Fetch raw data from external sources

- `slack.py`: Slack API interactions

  - Fetch messages from channels
  - Handle threading and pagination
  - Filter relevant messages (mentions, DMs)

- `linear.py`: Linear API interactions
  - Fetch issues by team/assignee
  - Create issues and add comments
  - Manage issue states

**Key Principle:** These modules only fetch/push dataâ€”no business logic

---

### **Storage Layer** (`app/storage/`)

**Purpose:** Manage data persistence

- `db.py`: SQLite database operations
  - Store Slack messages with deduplication
  - Track processed status
  - Query messages by time/status
  - Provide database statistics

**Key Principle:** Pure CRUD operationsâ€”no knowledge of business rules

---

### **AI Layer** (`app/ai/`)

**Purpose:** Intelligent analysis and decision-making

- `analyzer.py`: AI-powered message analysis
  - Match messages to existing issues (semantic similarity)
  - Detect new work requests
  - Provide reasoning for suggestions
  - Batch processing for efficiency

**Key Principle:** Encapsulates all AI/LLM logic in one place

---

### **Workflows Layer** (`app/jobs/workflows/`)

**Purpose:** Orchestrate business logic by combining layers

- `sync.py`: **Sync Workflow**

  ```
  Slack API â†’ Database â†’ Return stats
  ```

  Fetches last 24h of messages and stores them

- `process.py`: **Process Workflow**

  ```
  Database â†’ AI Analyzer â†’ Linear API â†’ Database (mark processed)
  ```

  Analyzes unprocessed messages and syncs with Linear

- `standup.py`: **Standup Workflow**
  ```
  Linear API + Database â†’ Generate report data
  ```
  Aggregates issues and messages for daily standup

**Key Principle:** Workflows know about all layers and orchestrate them

---

## ğŸ”„ Data Flow

### Typical Daily Flow:

1. **Morning Sync**

   ```
   cli.py sync â†’ workflows/sync.py â†’ ingestion/slack.py â†’ storage/db.py
   ```

2. **Process Messages**

   ```
   cli.py process â†’ workflows/process.py
   â”œâ”€â†’ storage/db.py (get unprocessed)
   â”œâ”€â†’ ingestion/linear.py (get issues)
   â”œâ”€â†’ ai/analyzer.py (match messages to issues)
   â””â”€â†’ ingestion/linear.py (add comments, create issues)
   ```

3. **Daily Standup**
   ```
   cli.py standup â†’ workflows/standup.py
   â”œâ”€â†’ ingestion/linear.py (get issues)
   â””â”€â†’ storage/db.py (get messages)
   ```

---

## ğŸ¯ Benefits of This Architecture

âœ… **Separation of Concerns**

- Each layer has a single, clear responsibility
- Easy to understand what goes where

âœ… **Testable**

- Can test each layer independently
- Mock external APIs for workflow testing

âœ… **Extensible**

- Add GitHub ingestion without touching workflows
- Add new workflows without changing ingestion
- Swap AI providers without affecting workflows

âœ… **Maintainable**

- Bug in Slack API? Check `ingestion/slack.py`
- Need to change AI logic? Check `ai/analyzer.py`
- Want new workflow? Add to `workflows/`

âœ… **Reusable**

- Workflows can use same ingestion modules
- Multiple workflows can share AI analyzer
- CLI and future API can use same workflows

---

## ğŸš€ Adding New Features

### Add New Data Source (e.g., GitHub)

1. Create `app/jobs/workflows/ingestion/github.py`
2. Implement fetch methods
3. Use in existing or new workflows

### Add New Workflow

1. Create `app/jobs/workflows/my_workflow.py`
2. Import needed ingestion/storage/ai modules
3. Orchestrate the business logic
4. Add CLI command in `cli.py`

### Change AI Provider

1. Update `app/ai/analyzer.py`
2. All workflows automatically use new logic
3. No changes needed elsewhere

---

## ğŸ“ Example: Adding GitHub Support

```python
# 1. Create app/jobs/workflows/ingestion/github.py
class GitHubClient:
    def fetch_pull_requests(self):
        # Fetch PRs from GitHub API
        pass

# 2. Use in workflow
from ..ingestion.github import GitHubClient

def sync_github():
    github = GitHubClient()
    prs = github.fetch_pull_requests()
    # Store in DB, analyze, etc.
```

No changes needed to existing code!
